---
title: "02: Fingerprinting Encrypted Voice Traffic on Smart Speakers with Deep Learning by C. Wang, S. Kennedy, H. Li, K. Hudson, G. Atluri, X. Wei, W. Sun, and B. Wang"
date: 2020-10-21
type: book
commentable: true

# Provide the name of the presenter
summary: "Presenters: Brian Lu and Matthew Sahara"

# Provide other tags that describe the paper
tags:
- teaching
- ee693e
- wireless fingerprinting
- deep learning
---

***
## Paper Summary
Smart speaker devices are steadily growing in popularity across the globe, and there also exists a growing need to ensure user privacy when using these systems. This featured work explores the application of fingerprinting on encrypted traffic of various smart speakers, using different types of neural networks. Data collection of network traffic is automated using a Raspberry Pi for the emulation of a voice command, alongside a smart speaker with an internet connection. Large datasets are generated from different popular smart speakers (Google Home, Amazon Echo) under closed-world and open-world conditions. Methods used for fingerprinting of encrypted traffic include: Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), Stacked AutoEncoder (SAE), and Ensemble Learning. The paper also outlines a defense method to combat fingerprinting, using novel adaptive padding, which leverages dummy packets and the randomization of obfuscated packet lengths.
***

## Presentation
{{< youtube YupirjAVxFU >}}
***

## Review
### Strengths
- They generated large datasets for both controlled and real-world situations, also including trials with varied voice pitch and timbre.
- Different types of neural networks were trained to fingerprint the encrypted traffic and then compared to determine the most accurate method.
- A solution using adaptive padding and randomization of dummy packets was suggested and tested to reduce the effectiveness of the exposed exploitation.

### Weaknesses
- A wider breadth and comparison of smart speakers, or even smart home devices, would help to demonstrate the versatility of this fingerprinting method using neural networks.
- A more in-depth analysis of target devices would help to solidify the slight differences between the two featured. There must be more unique side-channel information that is specific to the type of smart speaker in use.

### Detailed Comments
**Strengths:** Among many novel ideas, the paper introduced an automated form of data collection using a Raspberry Pi. Speaking from my personal experiences with the collection of drone traffic, manual data collection is a very taxing process. By creating a method to generate sounds with a external speaker and subsequently, record the traffic from the smart speaker, the authors were able to able to continuously collect large datasets in a closed-world, experimental environment. This not only made it easier on the authors, but it also served as a way to make the experimental data much more consistent and accurate. This provided a solid baseline for the other parts of the experiment. In addition, it was noted that there were slight discrepancies between the voice command verbiage of the Google Home and that of the Amazon Echo. Therefore, separate datasets were recorded to provide an accurate comparison.

This paper featured and compared the following methods: Convolutional Neural Network, Long Short-Term Memory, Stacked AutoEncoder, and Ensemble Learning for the fingerprinting of encrypted data. The strengths of the fingerprinting methods were outlined and the accuracy of these neural networks were later compared. In addition, a simple, yet effective solution using adaptive padding and dummy packets was used to decrease the accuracy of these neural networks.

**Weaknesses:** We think this paper was well written and comprehensive for the two speakers that it focused on. Methods not explored by this paper include training and applying these neural network architectures to a wider range of smart speakers and smart home devices. This would demonstrate that this method of fingerprinting can be used on a broader scale. Consequently, more solutions to these side-channel issues will have to be produced. Additionally, smart speakers must have some variation in the way that they communicate, and further information should be able to be extracted.

### Implementation
The following figure is a system level overview of a fingerprinting attack on a smart speaker handling voice command traffic.
{{< figure src="https://github.com/gustybear-teaching/course_ee693e_2020_fall/raw/main/week_09/images/smartspeaker_1_overview.png" title="[System Overview]" width="600" >}}
The system overview shows how a user speaks to send a voice command, which is recorded by the speaker and sent to a cloud server for speech recognition and processing, before the response is subsequently sent back to the speaker. An attacker can perform a man-in-the-middle attack to infer information about the speaker, based on metadata or packet headers, in the IP-based wireless network. Additionally, the attacker can analyze a large dataset using a neural network and fingerprint the traffic to ultimately achieve a breach in privacy.

{{< figure src="https://github.com/gustybear-teaching/course_ee693e_2020_fall/raw/main/week_09/images/smartspeaker_2_datacollect.png" title="[Automated Closed-World Data Collection]" width="300" >}}
Beginning the experimental phase, the paper showcases an automated system in an experimental environment to collect datasets with an external speaker, Raspberry Pi, smart speaker, and internet connection. The Pi uses the external speaker to produce a prerecorded/emulated voice command, which is tested with a variety of voice variations. Subsequently, the smart speaker processes and responds to the voice command via the Pi's network connection. This is a good way to optimize the data collection process in a closed-world setting as baseline dataset.

{{< figure src="https://github.com/gustybear-teaching/course_ee693e_2020_fall/raw/main/week_09/images/smartspeaker_9_nndiagram.png" title="[CNN and LSTM Structure Diagram]" width="300" >}}
The CNN and LSTM structures are shown above. In the CNN, we see that convolution and pooling are performed multiple times. On the other hand, looking at the LSTM, we note that LSTM structures are typically used for sequential data, and we see its characteristic recursive quality.

{{< figure src="https://github.com/gustybear-teaching/course_ee693e_2020_fall/raw/main/week_09/images/smartspeaker_10_saediagram.png" title="[SAE Structure Diagram]" width="300" >}}
Looking at the SAE structure, we see that it consists of multiple layers of sparse autoencoders, where the input is encoded then decoded for output.

{{< figure src="https://github.com/gustybear-teaching/course_ee693e_2020_fall/raw/main/week_09/images/smartspeaker_5_padding.png" title="[Defense Obfuscation of Packets]" width="300" >}}
Looking at the proposed defense against voice command fingerprinting attacks, the above diagram shows how on-the-fly obfuscation of individial packets is achieved. Starting with typical adaptive padding, using dummy packets with no latency, another layer of differential privacy (using a privacy parameter) is invoked on the packet. Essentially, an additional layer of noise is added to packets to further randomize the data and prevent fingerprinting.

An in-depth look at the raw code can be viewed at: [GitHub: DeepVCFingerprinting](https://github.com/SmartHomePrivacyProject/DeepVCFingerprinting)

### Experimentation
Experimental visualization of Amazon Echo data first began with the following heatmap of different traffic traces that show a relationship between packet size and type of question asked.
{{< figure src="https://github.com/gustybear-teaching/course_ee693e_2020_fall/raw/main/week_09/images/smartspeaker_3_heatmap.png" title="[Heatmap of Encrypted Traces]" width="300" >}}
Using this heatmap, the paper shows that different types of questions, such as confirmational (yes/no) answers compared to open-ended responses, yield different statistics regarding packet sizing. This shows that it is possible to infer some information based on packet sizing. Some of these differences are very subtle, thus creating a need for the application of neural networks.

{{< figure src="https://github.com/gustybear-teaching/course_ee693e_2020_fall/raw/main/week_09/images/smartspeaker_4_neuralnetworks.png" title="[Neural Network Accuracy Based on Data Size]" width="300" >}}
In the above figure, we compare the accuracy of the different neural network types in respect to the number of traffic traces fed in. CNS19 and CUMUL are other existing methods. The results of the paper show that the CNN and the LSTM are the highest performing in this comparison, using closed-world data.

{{< figure src="https://github.com/gustybear-teaching/course_ee693e_2020_fall/raw/main/week_09/images/smartspeaker_6_privacyparams.png" title="[Neural Network Accuracy with Privacy Parameter]" width="300" >}}
We also observe the effect of the *privacy parameter* suggested to defend against fingerprinting attacks. We notice a significant drop in accuracy. Note that the effect of the privacy parameter is not as significant in the binary format, as the parameter does not affect binary input. According to the paper, minor changes in the binary format can be attributed to the probabilistic algorithm of adaptive padding.

### Audience Questions
1. This paper mentioned that they could leverage packet timing, which they are interested for future work. How would this help improve experimental results?

Depending on the format of the data sent, this may not be relevant. If packet timing was a characteristic factor, the variation of packet timing, in addition to the dummy packets mentioned, could help to obfuscate the traffic more and ultimately weaken the extracted fingerprint.

2. Whether their attacks will be effective on human voices in the real world?

Various distinct emulated voices (male, female, different pitches) were used in the formation of the closed-world dataset. Real voices were used in the open-world dataset. Both cases demonstrated favorable results in terms of fingerprinting; therefore, yes, the fingerprinting methods outlined in the paper were tested in the real world. If this question is referring to the encrypted voice traffic, we discussed that further voice traffic characteristics could theoretically be extrapolated based on how the data is divided/encapsulated.

3. Can this technique be applied to other smart speakers made by different manufacturers?

Yes this techniques can be applied to smart speakers made by different manufacturers. It is important to note that the Home and Echo have slightly different commands. Likewise, the neural network would have to be retrained for each specific type of smart speaker.

4. Since a simple package padding would easily break the attack. Will this attack be economically viable?

This paper focused on identifying a specific issue and provided a simple countermeasure. It may be economically viable, but there may be some slight latency introduced when further trying to obfuscate the data. In summary, this fingerprinting method was introduced as a proof-of-concept and stands to provoke further thought on the extrapolation of side-channel information, especially pertaining to the privacy of your own home.

5. What are some ways the obfuscation defence can be improved?

Utility vs. Security trade-off. Further quantitative work should be done on this solution to determine the optimal point at which there is enough noise in the data to deter potential attacks, while also preserving the speed and minimizing the complexity for a positive user experience.

6. What can an attacker do to obtain more information after identifying the fingerprinting of those voice commands?

More capabilities of smart homes, including additional features in smart speakers, lead to more qualities, pieces, and patterns that can be analyzed to distinguish a person, eventually resulting in a privacy breach. The fingerprinting of smart speakers can play a part in the overall characterization of a home and person.

7. Could this be trained to eventually fingerprint simple phrases that aren't also voice commands?

Yes, this would be interesting to look into. The paper actually outlines an existing social issue where Amazon employees overheard a potential crime being committed via an Alexa, and they were told to stand down and do absolutely nothing. While there presents a social dilemma, it also serves to show that audio not associated with commands can be analyzed. There may be realizable limitations in terms of dataset size and computing power, but it is nonetheless a very interesting idea.

8. How would this attack fair in an ecosystem of different smart devices? What if the target had a variety of smart devices connected to the network?

In an ecosystem of different smart devices, it is not too difficult to identify different devices connected to the same IP-based network. In an integrated network, such as one with interconnected devices communicating through a variety of protocols, such as Bluetooth or Zigbee simultaenously, a significant level of difficultly is definitely presented.
